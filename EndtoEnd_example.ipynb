{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ze3SSQc0BKLB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pytorch-tabnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a demo notebook that provides an example of how to classify between competitive and cooperative environments. In this notebook we use the [TabNet model](https://pypi.org/project/pytorch-tabnet/).\n",
        "\n",
        "This is a binary classification task, where 1 is a label for facultative cooperation and 0 is a label for competition.\n",
        "\n",
        "Data is stored in $\\texttt{.csv}$ fromat as a table, where chemical compounds are assigned to the column names and rows represent the environment."
      ],
      "metadata": {
        "id": "TDIE0ETCG_Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import joblib\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# ml frameworks\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.datasets import make_classification # for test of funcs\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_curve,\n",
        "    auc,\n",
        "    RocCurveDisplay,\n",
        "    PrecisionRecallDisplay,\n",
        ")\n",
        "\n",
        "import torch\n",
        "#time management\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "#stats\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.spatial.distance import cdist\n",
        "from itertools import combinations\n",
        "#download data from hub\n",
        "from huggingface_hub import hf_hub_download"
      ],
      "metadata": {
        "id": "_RE6AuYOBgfe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from pytorch_tabnet.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "UUSU-CKFCLvx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXPkXDEUCLyA",
        "outputId": "61cd10d3-4aed-402f-9348-5611467f36f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the data from our [HugginFace repo](https://huggingface.co/datasets/powidla/Friend-Or-Foe)."
      ],
      "metadata": {
        "id": "zY1GOC4hIOSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPO_ID = \"powidla/Friend-Or-Foe\"\n",
        "\n",
        "# File paths within the repo\n",
        "X_train_ID = \"Classification/AGORA/100/BC-I/X_train_BC-I-100.csv\"\n",
        "X_val_ID = \"Classification/AGORA/100/BC-I/X_val_BC-I-100.csv\"\n",
        "X_test_ID = \"Classification/AGORA/100/BC-I/X_test_BC-I-100.csv\"\n",
        "\n",
        "y_train_ID = \"Classification/AGORA/100/BC-I/y_train_BC-I-100.csv\"\n",
        "y_val_ID = \"Classification/AGORA/100/BC-I/y_val_BC-I-100.csv\"\n",
        "y_test_ID = \"Classification/AGORA/100/BC-I/y_test_BC-I-100.csv\"\n",
        "\n",
        "# Download and load CSVs as pandas DataFrames\n",
        "X_train = pd.read_csv(hf_hub_download(repo_id=REPO_ID, filename=X_train_ID, repo_type=\"dataset\"))\n",
        "X_val = pd.read_csv(hf_hub_download(repo_id=REPO_ID, filename=X_val_ID, repo_type=\"dataset\"))\n",
        "X_test = pd.read_csv(hf_hub_download(repo_id=REPO_ID, filename=X_test_ID, repo_type=\"dataset\"))\n",
        "\n",
        "y_train = pd.read_csv(hf_hub_download(repo_id=REPO_ID, filename=y_train_ID, repo_type=\"dataset\"))\n",
        "y_val = pd.read_csv(hf_hub_download(repo_id=REPO_ID, filename=y_val_ID, repo_type=\"dataset\"))\n",
        "y_test = pd.read_csv(hf_hub_download(repo_id=REPO_ID, filename=y_test_ID, repo_type=\"dataset\"))"
      ],
      "metadata": {
        "id": "9nMCt3JJCS3w"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing top 10 environments from dataframe"
      ],
      "metadata": {
        "id": "s13nDtCdKZAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(10)"
      ],
      "metadata": {
        "id": "I1rV18OxKYUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The abbreviation names of compounds play role of column names"
      ],
      "metadata": {
        "id": "9pfWpmkOLYLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns.values"
      ],
      "metadata": {
        "id": "q_rJ9c4pLhjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract values from DataFrame and fix shape of labels"
      ],
      "metadata": {
        "id": "a7Zvj65_LlEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.values\n",
        "X_val = X_val.values\n",
        "X_test = X_test.values\n",
        "\n",
        "y_train = y_train.values.reshape(-1)\n",
        "y_val = y_val.values.reshape(-1)\n",
        "y_test = y_test.values.reshape(-1)"
      ],
      "metadata": {
        "id": "OtqtMJXDCS6T"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_confusion_matrix(y_true, y_pred):\n",
        "    '''\n",
        "    Description: Create a confusion matrix.\n",
        "    Arguments: y_true (array-like): Ground truth labels;\n",
        "               y_pred (array-like): Predicted labels.\n",
        "    Outputs:\n",
        "        pd.DataFrame: A confusion matrix as a pandas DataFrame.\n",
        "    '''\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_df = pd.DataFrame(cm, index=[\"True Negative\", \"True Positive\"],\n",
        "                             columns=[\"Predicted Negative\", \"Predicted Positive\"])\n",
        "    return cm_df\n",
        "\n",
        "\n",
        "def score_metrics(y_true, y_pred, y_prob):\n",
        "    '''\n",
        "    Description: Calculate various metrics for binary classification.\n",
        "    Arguments: y_true (array-like): Ground truth labels;\n",
        "               y_pred (array-like): Predicted labels;\n",
        "               y_prob (array-like): Predicted probabilities for the positive class.\n",
        "    Outputs:\n",
        "        dict\n",
        "    '''\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"ROC AUC\": roc_auc_score(y_true, y_prob),\n",
        "        \"Precision\": precision_score(y_true, y_pred),\n",
        "        \"Recall\": recall_score(y_true, y_pred),\n",
        "        \"F1 Score\": f1_score(y_true, y_pred),\n",
        "        \"MCC\": matthews_corrcoef(y_true, y_pred),\n",
        "    }\n",
        "    # PR AUC\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
        "    metrics[\"PR AUC\"] = auc(recall, precision)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def train_and_evaluate_tabnet(X_train, y_train, X_val, y_val, X_test, y_test,\n",
        "                             output_dir=\"tabnet_results\", seed=4221,\n",
        "                             max_epochs=100, patience=10):\n",
        "    '''\n",
        "    Description: Train and evaluate TabNet on binclass.\n",
        "\n",
        "    Arguments:\n",
        "        X_train, y_train: Training data\n",
        "        X_val, y_val: Validation data\n",
        "        X_test, y_test: Test data\n",
        "        output_dir: Directory to save results\n",
        "        seed: Random seed\n",
        "\n",
        "    Outputs:\n",
        "        json\n",
        "    '''\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Init\n",
        "    clf = TabNetClassifier(\n",
        "        cat_idxs=[],\n",
        "        cat_dims=[],\n",
        "        cat_emb_dim=1,\n",
        "        optimizer_fn=torch.optim.AdamW,\n",
        "        optimizer_params=dict(lr=1e-4, weight_decay=0.02),\n",
        "        scheduler_params={\"step_size\":50, \"gamma\":0.99},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "        mask_type='entmax',\n",
        "        n_d=64,\n",
        "        n_a=64,\n",
        "        seed=seed,\n",
        "        device_name=device\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    clf.fit(\n",
        "        X_train=X_train, y_train=y_train,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric=['accuracy'],\n",
        "        max_epochs=max_epochs,\n",
        "        patience=patience,\n",
        "        batch_size=1024\n",
        "    )\n",
        "\n",
        "    # Test\n",
        "    y_pred = clf.predict(X_test)\n",
        "    y_proba = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"ROC AUC\": roc_auc_score(y_test, y_proba),\n",
        "        \"Recall\": recall_score(y_test, y_pred),\n",
        "        \"F1\": f1_score(y_test, y_pred),\n",
        "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(output_dir, \"tabnet_metrics.json\"), 'w') as f:\n",
        "        json.dump(metrics, f, indent=4)\n",
        "\n",
        "    clf.save_model(os.path.join(output_dir, \"tabnet_model.zip\"))\n",
        "\n",
        "    print(f\"\\nTest Metrics:\")\n",
        "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(f\"MCC: {metrics['MCC']:.4f}\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "QFUrp-TvCS9U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ERIKH82OCanZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the baseline TabNet model and scoring accuracy. Final output is $\\texttt{.json}$ file with metrics for binclass"
      ],
      "metadata": {
        "id": "JV3G6Z5aIdWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate_tabnet(X_train, y_train, X_val, y_val, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "722uxXIHCaqa",
        "outputId": "fa6a3a91-9e2a-4f52-a69c-7a3fd650c673"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 1.79555 | val_0_accuracy: 0.57577 |  0:00:56s\n",
            "epoch 1  | loss: 1.01109 | val_0_accuracy: 0.644   |  0:01:54s\n",
            "epoch 2  | loss: 0.85879 | val_0_accuracy: 0.65267 |  0:02:53s\n",
            "epoch 3  | loss: 0.81467 | val_0_accuracy: 0.65717 |  0:03:55s\n",
            "epoch 4  | loss: 0.78939 | val_0_accuracy: 0.65788 |  0:04:55s\n",
            "epoch 5  | loss: 0.769   | val_0_accuracy: 0.65998 |  0:05:52s\n",
            "epoch 6  | loss: 0.7535  | val_0_accuracy: 0.66097 |  0:06:54s\n",
            "epoch 7  | loss: 0.7441  | val_0_accuracy: 0.66209 |  0:07:55s\n",
            "epoch 8  | loss: 0.73    | val_0_accuracy: 0.66402 |  0:08:58s\n",
            "epoch 9  | loss: 0.72586 | val_0_accuracy: 0.66664 |  0:09:58s\n",
            "epoch 10 | loss: 0.71568 | val_0_accuracy: 0.66868 |  0:10:54s\n",
            "epoch 11 | loss: 0.70933 | val_0_accuracy: 0.66983 |  0:11:52s\n",
            "epoch 12 | loss: 0.70222 | val_0_accuracy: 0.66637 |  0:12:48s\n",
            "epoch 13 | loss: 0.69702 | val_0_accuracy: 0.66735 |  0:13:43s\n",
            "epoch 14 | loss: 0.69188 | val_0_accuracy: 0.66984 |  0:14:39s\n",
            "epoch 15 | loss: 0.68661 | val_0_accuracy: 0.67067 |  0:15:34s\n",
            "epoch 16 | loss: 0.68232 | val_0_accuracy: 0.6719  |  0:16:30s\n",
            "epoch 17 | loss: 0.67741 | val_0_accuracy: 0.67303 |  0:17:26s\n",
            "epoch 18 | loss: 0.67388 | val_0_accuracy: 0.67226 |  0:18:33s\n",
            "epoch 19 | loss: 0.67023 | val_0_accuracy: 0.67337 |  0:19:36s\n",
            "epoch 20 | loss: 0.66619 | val_0_accuracy: 0.67482 |  0:20:34s\n",
            "epoch 21 | loss: 0.66315 | val_0_accuracy: 0.67447 |  0:21:29s\n",
            "epoch 22 | loss: 0.65993 | val_0_accuracy: 0.67496 |  0:22:32s\n",
            "epoch 23 | loss: 0.65714 | val_0_accuracy: 0.67456 |  0:23:39s\n",
            "epoch 24 | loss: 0.65519 | val_0_accuracy: 0.67545 |  0:24:34s\n",
            "epoch 25 | loss: 0.65281 | val_0_accuracy: 0.67662 |  0:25:32s\n",
            "epoch 26 | loss: 0.6499  | val_0_accuracy: 0.67539 |  0:26:27s\n",
            "epoch 27 | loss: 0.64903 | val_0_accuracy: 0.67518 |  0:27:24s\n",
            "epoch 28 | loss: 0.64737 | val_0_accuracy: 0.67639 |  0:28:20s\n",
            "epoch 29 | loss: 0.6452  | val_0_accuracy: 0.67755 |  0:29:17s\n",
            "epoch 30 | loss: 0.64385 | val_0_accuracy: 0.67645 |  0:30:13s\n",
            "epoch 31 | loss: 0.64295 | val_0_accuracy: 0.67593 |  0:31:08s\n",
            "epoch 32 | loss: 0.64133 | val_0_accuracy: 0.67677 |  0:32:04s\n",
            "epoch 33 | loss: 0.63916 | val_0_accuracy: 0.67714 |  0:32:59s\n",
            "epoch 34 | loss: 0.6392  | val_0_accuracy: 0.67721 |  0:33:55s\n",
            "epoch 35 | loss: 0.6369  | val_0_accuracy: 0.67741 |  0:34:50s\n",
            "epoch 36 | loss: 0.6366  | val_0_accuracy: 0.67738 |  0:35:45s\n",
            "epoch 37 | loss: 0.63525 | val_0_accuracy: 0.67717 |  0:36:41s\n",
            "epoch 38 | loss: 0.63442 | val_0_accuracy: 0.67769 |  0:37:37s\n",
            "epoch 39 | loss: 0.63404 | val_0_accuracy: 0.67712 |  0:38:32s\n",
            "epoch 40 | loss: 0.63288 | val_0_accuracy: 0.67778 |  0:39:28s\n",
            "epoch 41 | loss: 0.63141 | val_0_accuracy: 0.6776  |  0:40:23s\n",
            "epoch 42 | loss: 0.63176 | val_0_accuracy: 0.67769 |  0:41:20s\n",
            "epoch 43 | loss: 0.63105 | val_0_accuracy: 0.67809 |  0:42:17s\n",
            "epoch 44 | loss: 0.62923 | val_0_accuracy: 0.67778 |  0:43:13s\n",
            "epoch 45 | loss: 0.62916 | val_0_accuracy: 0.67786 |  0:44:08s\n",
            "epoch 46 | loss: 0.62863 | val_0_accuracy: 0.67799 |  0:45:04s\n",
            "epoch 47 | loss: 0.62819 | val_0_accuracy: 0.67784 |  0:45:59s\n",
            "epoch 48 | loss: 0.62731 | val_0_accuracy: 0.6778  |  0:46:55s\n",
            "epoch 49 | loss: 0.62674 | val_0_accuracy: 0.67772 |  0:47:50s\n",
            "epoch 50 | loss: 0.62601 | val_0_accuracy: 0.67839 |  0:48:46s\n",
            "epoch 51 | loss: 0.62558 | val_0_accuracy: 0.67816 |  0:49:41s\n",
            "epoch 52 | loss: 0.62517 | val_0_accuracy: 0.67844 |  0:50:39s\n",
            "epoch 53 | loss: 0.62416 | val_0_accuracy: 0.6785  |  0:51:37s\n",
            "epoch 54 | loss: 0.62467 | val_0_accuracy: 0.67855 |  0:52:34s\n",
            "epoch 55 | loss: 0.6227  | val_0_accuracy: 0.67852 |  0:53:29s\n",
            "epoch 56 | loss: 0.62315 | val_0_accuracy: 0.67867 |  0:54:24s\n",
            "epoch 57 | loss: 0.62242 | val_0_accuracy: 0.67888 |  0:55:20s\n",
            "epoch 58 | loss: 0.62258 | val_0_accuracy: 0.67847 |  0:56:16s\n",
            "epoch 59 | loss: 0.62166 | val_0_accuracy: 0.67925 |  0:57:11s\n",
            "epoch 60 | loss: 0.62125 | val_0_accuracy: 0.67879 |  0:58:07s\n",
            "epoch 61 | loss: 0.62092 | val_0_accuracy: 0.67901 |  0:59:02s\n",
            "epoch 62 | loss: 0.62039 | val_0_accuracy: 0.67942 |  0:59:57s\n",
            "epoch 63 | loss: 0.61968 | val_0_accuracy: 0.67999 |  1:00:53s\n",
            "epoch 64 | loss: 0.61987 | val_0_accuracy: 0.67982 |  1:01:49s\n",
            "epoch 65 | loss: 0.61902 | val_0_accuracy: 0.67945 |  1:02:44s\n",
            "epoch 66 | loss: 0.61842 | val_0_accuracy: 0.68003 |  1:03:40s\n",
            "epoch 67 | loss: 0.61846 | val_0_accuracy: 0.67986 |  1:04:35s\n",
            "epoch 68 | loss: 0.61733 | val_0_accuracy: 0.68048 |  1:05:31s\n",
            "epoch 69 | loss: 0.61714 | val_0_accuracy: 0.68046 |  1:06:26s\n",
            "epoch 70 | loss: 0.61643 | val_0_accuracy: 0.68074 |  1:07:22s\n",
            "epoch 71 | loss: 0.61585 | val_0_accuracy: 0.68112 |  1:08:19s\n",
            "epoch 72 | loss: 0.61533 | val_0_accuracy: 0.68155 |  1:09:18s\n",
            "epoch 73 | loss: 0.61462 | val_0_accuracy: 0.6819  |  1:10:15s\n",
            "epoch 74 | loss: 0.61372 | val_0_accuracy: 0.68279 |  1:11:10s\n",
            "epoch 75 | loss: 0.61315 | val_0_accuracy: 0.68365 |  1:12:06s\n",
            "epoch 76 | loss: 0.61322 | val_0_accuracy: 0.68284 |  1:13:05s\n",
            "epoch 77 | loss: 0.61266 | val_0_accuracy: 0.68392 |  1:14:02s\n",
            "epoch 78 | loss: 0.61195 | val_0_accuracy: 0.68461 |  1:14:59s\n",
            "epoch 79 | loss: 0.61152 | val_0_accuracy: 0.68463 |  1:15:58s\n",
            "epoch 80 | loss: 0.61154 | val_0_accuracy: 0.68512 |  1:16:54s\n",
            "epoch 81 | loss: 0.61072 | val_0_accuracy: 0.6859  |  1:17:49s\n",
            "epoch 82 | loss: 0.60933 | val_0_accuracy: 0.68687 |  1:18:45s\n",
            "epoch 83 | loss: 0.60856 | val_0_accuracy: 0.68749 |  1:19:41s\n",
            "epoch 84 | loss: 0.60785 | val_0_accuracy: 0.68832 |  1:20:37s\n",
            "epoch 85 | loss: 0.60772 | val_0_accuracy: 0.68825 |  1:21:32s\n",
            "epoch 86 | loss: 0.60694 | val_0_accuracy: 0.6889  |  1:22:28s\n",
            "epoch 87 | loss: 0.60638 | val_0_accuracy: 0.68992 |  1:23:24s\n",
            "epoch 88 | loss: 0.60561 | val_0_accuracy: 0.69093 |  1:24:19s\n",
            "epoch 89 | loss: 0.60449 | val_0_accuracy: 0.69206 |  1:25:15s\n",
            "epoch 90 | loss: 0.60366 | val_0_accuracy: 0.69169 |  1:26:11s\n",
            "epoch 91 | loss: 0.60381 | val_0_accuracy: 0.69198 |  1:27:06s\n",
            "epoch 92 | loss: 0.60323 | val_0_accuracy: 0.69324 |  1:28:02s\n",
            "epoch 93 | loss: 0.60191 | val_0_accuracy: 0.69329 |  1:28:58s\n",
            "epoch 94 | loss: 0.6013  | val_0_accuracy: 0.69375 |  1:29:54s\n",
            "epoch 95 | loss: 0.60034 | val_0_accuracy: 0.69424 |  1:30:52s\n",
            "epoch 96 | loss: 0.59951 | val_0_accuracy: 0.69517 |  1:31:48s\n",
            "epoch 97 | loss: 0.59932 | val_0_accuracy: 0.69537 |  1:32:44s\n",
            "epoch 98 | loss: 0.59879 | val_0_accuracy: 0.69561 |  1:33:40s\n",
            "epoch 99 | loss: 0.597   | val_0_accuracy: 0.69658 |  1:34:36s\n",
            "Stop training because you reached max_epochs = 100 with best_epoch = 99 and best_val_0_accuracy = 0.69658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved model at tabnet_results/tabnet_model.zip.zip\n",
            "\n",
            "Test Metrics:\n",
            "Accuracy: 0.6962\n",
            "MCC: 0.1901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.6962477209003018,\n",
              " 'Precision': 0.7013915379894847,\n",
              " 'ROC AUC': np.float64(0.6500135335647999),\n",
              " 'Recall': 0.9587168442530039,\n",
              " 'F1': 0.8101108205702902,\n",
              " 'MCC': np.float64(0.19006778546753422)}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}